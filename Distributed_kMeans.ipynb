{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Node(object):\n",
    "    def __init__(self,number,neighbors,degree):\n",
    "        self.name = number\n",
    "        self.neighbors = neighbors\n",
    "        self.degree = degree\n",
    "        self.data = None                       #Holds the local data Pi\n",
    "        self.centers = None                    #Holds the centers Bi\n",
    "        self.local_coreset = None              #To store coreset, i.e. Si U Ai\n",
    "        self.weights = None                    #To store the weight of points in local coreset Si U Ai\n",
    "        self.message_received = {}\n",
    "        self.X = None                          #To store the final centers\n",
    "    def set_data(self,data):\n",
    "        self.data = data\n",
    "    def set_centers(self,centers):\n",
    "        self.centers = centers\n",
    "    def set_local_coreset(self,S):\n",
    "        self.local_coreset = S\n",
    "    def set_weights(self,weights):\n",
    "        self.weights = weights\n",
    "    def set_X(self,X):\n",
    "        self.X = X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_random_graph(no_of_nodes,probability):\n",
    "    return nx.erdos_renyi_graph(no_of_nodes,probability)\n",
    "\n",
    "def create_preferential_graph(n,m):\n",
    "    # n = number of nodes, m = number of edges \n",
    "    return nx.generators.random_graphs.barabasi_albert_graph(n,m)\n",
    "\n",
    "def create_grid_graph(n,m):\n",
    "    return nx.grid_2d_graph(n,m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Incomplete\n",
    "def uniform_partitioning(df,nodes):\n",
    "    temp_df = df.copy(deep=True)\n",
    "    size_of_pi = math.floor(df.shape[0]/len(nodes))\n",
    "    for node in nodes:\n",
    "        if node != nodes[-1]:\n",
    "            node.data = temp_df.sample(size_of_pi)\n",
    "            temp_df.drop(node.data.index,inplace = True)\n",
    "        else:\n",
    "            node.data = temp_df\n",
    "    return\n",
    "            \n",
    "def similarity_partitioning(df,nodes):\n",
    "    #code here\n",
    "    return\n",
    "\n",
    "def weighted_partitioning(df,nodes):\n",
    "    #code here\n",
    "    return\n",
    "\n",
    "def degree_partitioning(df,nodes):\n",
    "    #code here\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clustering_algo( data, no_of_centers ):\n",
    "    kmeans = KMeans(n_clusters=no_of_centers, init = 'random', random_state=0).fit(np.array(data))\n",
    "    #init stands for initialization, i.e. how to get first set of centers. Default is k-means++. I went for random\n",
    "    #random_state stands for the seed to generate random centers in the beginning. Kept it zero to get same centers everytime.\n",
    "    #Remove if not required\n",
    "    #The package uses LLoyd's algorithm\n",
    "    return pd.DataFrame(kmeans.cluster_centers_)      #this will contain a dataframe of centers, was an np array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Incomplete\n",
    "def Message_Passing(message,neighbors,node):\n",
    "    node.message_received[node] = message\n",
    "    for neighbor in neighbors:\n",
    "        for message in node.message_received.values():\n",
    "            neighbor.message_received[node] = message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_cost( data, centers):\n",
    "    distanceMatrix = pd.DataFrame(np.nan * np.ones(shape=(data.shape[0],centers.shape[0])))\n",
    "    for j in range(0, centers.shape[0]):\n",
    "        for i in range(0, data.shape[0]):\n",
    "            distanceMatrix.iloc[i][j] = sqrt((centers.iloc[j][0] – data.iloc[i][0])**2 + (centers.iloc[j][1] – data.iloc[i][1])**2)\n",
    "    #print (distanceMatrix)\n",
    "    return distanceMatrix.min(axis=1)\n",
    "\n",
    "def distributed_coreset_construction( nodes, t, no_of_centers ):\n",
    "    for node in nodes:\n",
    "        node.centers = clustering_algo(node.data, no_of_centers)    #this will contain centers stored in dataframe\n",
    "        cost_of_each_data = get_cost( node.data, node.centers)  #comes back as pandas series\n",
    "        Message_Passing(cost_of_each_data.sum(),node.neighbors,node)\n",
    "    for node in nodes:\n",
    "        t_i = (t*node.message_received[node])/sum(node.message_received.values())\n",
    "        m_p = 2*cost_of_each_data\n",
    "        S_i = node.data.sample(n=t_i,weights=m_p)\n",
    "        w_q = sum(node.cost_of_nodes.values())/(t*m_p[S_i.index])\n",
    "        w_b = []\n",
    "        for index, b in node.centers.iterrows():\n",
    "            Pb = node.data[np.sqrt(np.square(np.array(node.data) - np.array(b)).sum(1)) == cost_of_each_data]  \n",
    "            #previous line measures euc dist of each point with center b and compares the values with min cost i.e.min d(p,X)over all x belonging to X\n",
    "            #Pb will be a dataframe\n",
    "            w_b.append(Pb.shape[0] - sum([w_q[x] for x in list(map(lambda x:S_i.index.get_loc(x),S_i.index.intersection(Pb.index)))]))\n",
    "        node.set_local_coreset(pd.concat([S_i,node.centers]))\n",
    "        node.set_weight(w_q.extend(w_b))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def distributed_clustering_on_graph(nodes, t, no_of_centers):\n",
    "    distributed_coreset_construction( nodes, t, no_of_centers )\n",
    "    for v_i in nodes:\n",
    "        Message_Passing(node.local_coreset,node.neighbors,v_i)\n",
    "        node.set_X(clustering_algo( pd.concat(list(node.message_received.values())), no_of_centers ))\n",
    "    return(node.X)  #will return the centers obtained from last node called in for loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Practise cell\n",
    "#just testing out anything that i feel like adding to the codes above\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "df = pd.DataFrame({'a':[1,2,3,4,5,6,7],'b':[3,2,3,4,1,4,5]})\n",
    "df1 = pd.DataFrame({'a':[2,3,4,1,4,6,2],'b':[1,2,4,2,5,6,3]})\n",
    "#df.index.get_loc(df.head())\n",
    "l = pd.DataFrame({'a':[1,2,3,4,5,6,7],'b':[3,2,3,4,1,4,5]}).min(axis=1)\n",
    "k = df.tail(1)\n",
    "df[np.sqrt(np.square(np.array(df) - np.array(k)).sum(1)) == pd.Series(np.array([0,2,3,4,5 , 7, 0]))]\n",
    "test_index=pd.Index(list('23154'))\n",
    "j=[1,2,3,4,5,6,7,8]\n",
    "1-np.array([j[x] for x in list(map(lambda x:test_index.get_loc(x),pd.Index(['1','2','3'])))])\n",
    "k=pd.DataFrame()\n",
    "s={1:df,2:df1}\n",
    "pd.concat(list(s.values()))\n",
    "import networkx as nx\n",
    "j = nx.erdos_renyi_graph(10,0.3)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
