{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "from sklearn.cluster import KMeans, SpectralClustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Node(object):\n",
    "    def __init__(self,number,neighbors,degree):\n",
    "        self.name = number\n",
    "        self.neighbors = neighbors\n",
    "        self.degree = degree\n",
    "        self.data = None                       #Holds the local data Pi\n",
    "        self.centers = None                    #Holds the centers Bi\n",
    "        self.local_coreset = None              #To store coreset, i.e. Si U Ai\n",
    "        self.weights = None                    #To store the weight of points in local coreset Si U Ai\n",
    "        self.message_received = {}\n",
    "        self.X = None                          #To store the final centers\n",
    "    def set_data(self,data):\n",
    "        self.data = data\n",
    "    def set_centers(self,centers):\n",
    "        self.centers = centers\n",
    "    def set_local_coreset(self,S):\n",
    "        self.local_coreset = S\n",
    "    def set_weights(self,weights):\n",
    "        self.weights = weights\n",
    "    def set_X(self,X):\n",
    "        self.X = X\n",
    "        \n",
    "communication_cost = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_random_graph(no_of_nodes,probability):\n",
    "    return nx.erdos_renyi_graph(no_of_nodes,probability)\n",
    "\n",
    "def create_preferential_graph(n,m):\n",
    "    # n = number of nodes, m = number of edges \n",
    "    return nx.generators.random_graphs.barabasi_albert_graph(n,m)\n",
    "\n",
    "def create_grid_graph(n,m):\n",
    "    return nx.grid_2d_graph(n,m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to get sequence of iterating the nodes\n",
    "#Returns 'nodes' used in fuction arguements later in message passing\n",
    "def node_sequence(G):\n",
    "    seq=[]\n",
    "    l = list(nx.dfs_edges(G,0))\n",
    "    for i in range(len(l)-1):\n",
    "        if (l[i][1] == l[i+1][0]):\n",
    "            seq.append(l[i][0])\n",
    "        else:\n",
    "            seq.append(l[i][0])\n",
    "            seq.append(l[i][1])\n",
    "            p = nx.shortest_path(G,l[i][1],l[i+1][0])\n",
    "            for k in range(1,len(p)-1):\n",
    "                seq.append(p[k])\n",
    "    seq.append(l[-1][0])\n",
    "    seq.append(l[-1][1])\n",
    "    return seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Incomplete\n",
    "def uniform_partitioning(df,nodes):\n",
    "    temp_df = df.copy(deep=True)\n",
    "    size_of_pi = math.floor(df.shape[0]/len(nodes))\n",
    "    for node in nodes:\n",
    "        if node != nodes[-1]:\n",
    "            node.data = temp_df.sample(size_of_pi)\n",
    "            temp_df.drop(node.data.index,inplace = True)\n",
    "        else:\n",
    "            node.data = temp_df\n",
    "    return\n",
    "            \n",
    "def similarity_partitioning(df,nodes):\n",
    "    temp_df = df.copy(deep=True)\n",
    "    spec=SpectralClustering(n_clusters=len(nodes), gamma=1.0)\n",
    "    c_id = spec.fit_predict(temp_df)\n",
    "    for i in range(len(nodes)):\n",
    "        nodes[i].data = temp_df[c_id==i]      \n",
    "    return\n",
    "\n",
    "def weighted_partitioning(df,nodes):\n",
    "    #code here\n",
    "    return\n",
    "\n",
    "def degree_partitioning(df,nodes):\n",
    "    #code here\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clustering_algo( data, no_of_centers ):\n",
    "    kmeans = KMeans(n_clusters=no_of_centers, init = 'random', random_state=0).fit(np.array(data))\n",
    "    #init stands for initialization, i.e. how to get first set of centers. Default is k-means++. I went for random\n",
    "    #random_state stands for the seed to generate random centers in the beginning. Kept it zero to get same centers everytime.\n",
    "    #Remove if not required\n",
    "    #The package uses LLoyd's algorithm\n",
    "    return pd.DataFrame(kmeans.cluster_centers_)      #this will contain a dataframe of centers, was an np array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Message_Passing(message,neighbors,node):\n",
    "    global communication_cost\n",
    "    if node not in node.message_received: \n",
    "        node.message_received[node] = message\n",
    "    for neighbor in neighbors:\n",
    "        for message in node.message_received.values():\n",
    "            if node not in neighbor.message:\n",
    "                communication_cost+=1\n",
    "                neighbor.message_received[node] = message\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_cost( data, centers):\n",
    "    distanceMatrix = pd.DataFrame(np.nan * np.ones(shape=(data.shape[0],centers.shape[0])))\n",
    "    for j in range(0, centers.shape[0]):\n",
    "        for i in range(0, data.shape[0]):\n",
    "            distanceMatrix.iloc[i][j] = sqrt((centers.iloc[j][0] – data.iloc[i][0])**2 + (centers.iloc[j][1] – data.iloc[i][1])**2)\n",
    "    #print (distanceMatrix)\n",
    "    return distanceMatrix.min(axis=1)\n",
    "\n",
    "def distributed_coreset_construction( nodes, t, no_of_centers ):\n",
    "    for node in nodes:\n",
    "        node.centers = clustering_algo(node.data, no_of_centers)    #this will contain centers stored in dataframe\n",
    "        cost_of_each_data = get_cost( node.data, node.centers)  #comes back as pandas series\n",
    "        Message_Passing(cost_of_each_data.sum(),node.neighbors,node)\n",
    "    for node in nodes.reverse():\n",
    "        cost_of_each_data = get_cost( node.data, node.centers)  #comes back as pandas series\n",
    "        Message_Passing(cost_of_each_data.sum(),node.neighbors,node)\n",
    "    for node in nodes:\n",
    "        cost_of_each_data = get_cost( node.data, node.centers)  #comes back as pandas series\n",
    "        t_i = (t*node.message_received[node])/sum(node.message_received.values())\n",
    "        m_p = 2*cost_of_each_data\n",
    "        S_i = node.data.sample(n=t_i,weights=m_p)\n",
    "        w_q = sum(node.cost_of_nodes.values())/(t*m_p[S_i.index])\n",
    "        w_b = []\n",
    "        for index, b in node.centers.iterrows():\n",
    "            Pb = node.data[np.sqrt(np.square(np.array(node.data) - np.array(b)).sum(1)) == cost_of_each_data]  \n",
    "            #previous line measures euc dist of each point with center b and compares the values with min cost i.e.min d(p,X)over all x belonging to X\n",
    "            #Pb will be a dataframe\n",
    "            w_b.append(Pb.shape[0] - sum([w_q[x] for x in list(map(lambda x:S_i.index.get_loc(x),S_i.index.intersection(Pb.index)))]))\n",
    "        node.set_local_coreset(pd.concat([S_i,node.centers]))\n",
    "        node.set_weight(w_q.extend(w_b))\n",
    "    return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def distributed_clustering_on_graph(nodes, t, no_of_centers):\n",
    "    distributed_coreset_construction( nodes, t, no_of_centers )\n",
    "    for v_i in nodes:\n",
    "        Message_Passing(node.local_coreset,node.neighbors,v_i)\n",
    "    for v_i in nodes.reverse():\n",
    "        Message_Passing(node.local_coreset,node.neighbors,v_i)\n",
    "        node.set_X(clustering_algo( pd.concat(list(node.message_received.values())), no_of_centers ))\n",
    "    return(node.X)  #will return the centers obtained from last node called in for loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   a  b\n",
       "0  1  3\n",
       "1  2  2\n",
       "2  3  3\n",
       "3  4  4\n",
       "4  5  1\n",
       "5  6  4\n",
       "6  7  5"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Practise cell\n",
    "#just testing out anything that i feel like adding to the codes above\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "df = pd.DataFrame({'a':[1,2,3,4,5,6,7],'b':[3,2,3,4,1,4,5]})\n",
    "df1 = pd.DataFrame({'a':[2,3,4,1,4,6,2],'b':[1,2,4,2,5,6,3]})\n",
    "#df.index.get_loc(df.head())\n",
    "l = pd.DataFrame({'a':[1,2,3,4,5,6,7],'b':[3,2,3,4,1,4,5]}).min(axis=1)\n",
    "k = df.tail(1)\n",
    "df[np.sqrt(np.square(np.array(df) - np.array(k)).sum(1)) == pd.Series(np.array([0,2,3,4,5 , 7, 0]))]\n",
    "test_index=pd.Index(list('23154'))\n",
    "j=[1,2,3,4,5,6,7,8]\n",
    "1-np.array([j[x] for x in list(map(lambda x:test_index.get_loc(x),pd.Index(['1','2','3'])))])\n",
    "k=pd.DataFrame()\n",
    "s={1:df,2:df1}\n",
    "pd.concat(list(s.values()))\n",
    "import networkx as nx\n",
    "j = nx.erdos_renyi_graph(10,0.3)\n",
    "def f(): \n",
    "    global s\n",
    "    s+=1\n",
    "s = 0\n",
    "f()\n",
    "f()\n",
    "print(s)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 3])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(df.ix[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(df.ix[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1,  1])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(df.ix[0])-np.array(df.ix[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
